{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "from torchvision.transforms import functional as F\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from torchvision.models.detection import FasterRCNN_ResNet50_FPN_Weights\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Check if CUDA (GPU) is available and use it if possible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "# Load a pretrained Faster R-CNN model and move it to the appropriate device (GPU/CPU)\n",
    "model = fasterrcnn_resnet50_fpn(weights=FasterRCNN_ResNet50_FPN_Weights.COCO_V1)\n",
    "model.to(device)  # Move model to GPU (if available)\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "pipeline = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.Resize((800, 800)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(                   # Normalize based on ImageNet's statistics\n",
    "        mean=[0.485, 0.456, 0.406],         # Mean for ImageNet\n",
    "        std=[0.229, 0.224, 0.225]           # Std for ImageNet\n",
    "    ),\n",
    "])\n",
    "\n",
    "# Load COCO class labels (91 classes)\n",
    "coco_classes = [\n",
    "    \"__background__\", \"person\", \"bicycle\", \"car\", \"motorcycle\", \"airplane\", \"bus\",\n",
    "    \"train\", \"truck\", \"boat\", \"traffic light\", \"fire hydrant\", \"stop sign\",\n",
    "    \"parking meter\", \"bench\", \"bird\", \"cat\", \"dog\", \"horse\", \"sheep\", \"cow\",\n",
    "    \"elephant\", \"bear\", \"zebra\", \"giraffe\", \"backpack\", \"umbrella\", \"handbag\",\n",
    "    \"tie\", \"suitcase\", \"frisbee\", \"skis\", \"snowboard\", \"sports ball\", \"kite\",\n",
    "    \"baseball bat\", \"baseball glove\", \"skateboard\", \"surfboard\", \"tennis racket\",\n",
    "    \"bottle\", \"wine glass\", \"cup\", \"fork\", \"knife\", \"spoon\", \"bowl\", \"banana\",\n",
    "    \"apple\", \"sandwich\", \"orange\", \"broccoli\", \"carrot\", \"hot dog\", \"pizza\",\n",
    "    \"donut\", \"cake\", \"chair\", \"couch\", \"potted plant\", \"bed\", \"dining table\",\n",
    "    \"toilet\", \"TV\", \"laptop\", \"mouse\", \"remote\", \"keyboard\", \"cell phone\",\n",
    "    \"microwave\", \"oven\", \"toaster\", \"sink\", \"refrigerator\", \"book\", \"clock\",\n",
    "    \"vase\", \"scissors\", \"teddy bear\", \"hair drier\", \"toothbrush\"\n",
    "]\n",
    "\n",
    "# Open webcam feed\n",
    "cap = cv2.VideoCapture(1)  # my webcam is on index 1, you may need to change this\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Error: Could not read frame.\")\n",
    "        break\n",
    "\n",
    "    frame = cv2.flip(frame, 1)  # Flip the frame horizontally\n",
    "    # Convert the frame from BGR to RGB\n",
    "    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert the frame to a PyTorch tensor and add a batch dimension\n",
    "    input_tensor = pipeline(rgb_frame).unsqueeze(0)\n",
    "\n",
    "    # Move input tensor to the same device as the model (GPU or CPU)\n",
    "    input_tensor = input_tensor.to(device)\n",
    "\n",
    "    # Perform object detection\n",
    "    with torch.no_grad():\n",
    "        predictions = model(input_tensor)[0]  # Get predictions for the first image in batch\n",
    "\n",
    "    # Draw the bounding boxes and labels on the frame\n",
    "    for idx, box in enumerate(predictions[\"boxes\"]):\n",
    "        score = predictions[\"scores\"][idx].item()\n",
    "        label_idx = predictions[\"labels\"][idx].item()\n",
    "\n",
    "        # Only draw boxes for high-confidence detections\n",
    "        if score > 0.5:\n",
    "            # Extract box coordinates\n",
    "            x1, y1, x2, y2 = map(int, box)\n",
    "\n",
    "            # Check if label_idx is within the valid range\n",
    "            if 0 <= label_idx < len(coco_classes):\n",
    "                label = coco_classes[label_idx]\n",
    "            else:\n",
    "                label = \"Unknown\"\n",
    "\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "\n",
    "            # Add the label and score\n",
    "            label_text = f\"{label}: {score:.2f}\"\n",
    "            cv2.putText(frame, label_text, (x1, y1 - 10),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "    # Display the frame with detections\n",
    "    cv2.imshow(\"Object Detection\", frame)\n",
    "\n",
    "    # Exit the loop on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close all OpenCV windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
